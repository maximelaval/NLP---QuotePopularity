{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ili9I_lbD2NT",
    "outputId": "33af1757-dc91-429d-e3aa-5a41eb9c570b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import bz2\n",
    "import json\n",
    "import pandas as pd\n",
    "import string\n",
    "import time\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q_vT7TFMEeQ9",
    "outputId": "cace6447-9b53-487d-f92e-a44189286ef6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tld in /usr/local/lib/python3.7/dist-packages (0.12.6)\n",
      "Requirement already satisfied: pandas==1.3.0 in /usr/local/lib/python3.7/dist-packages (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.3.0) (1.19.5)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.3.0) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.3.0) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas==1.3.0) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tld\n",
    "%pip install pandas==1.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "zfNpHVT3n_hQ"
   },
   "outputs": [],
   "source": [
    "english_articles = [\"the\",\"a\",\"an\",\"some\",\"to\"]\n",
    "def count_words(s) : # this method returns the number of words in a string \n",
    "  return sum([ word.translate(str.maketrans('', '', string.punctuation)).isalpha()  for word in (s.replace('-',' ')).split()])\n",
    "  # the method makes sure to not include the english articles and the punctuation as a word.\n",
    "\n",
    "def average_word_length(s) :\n",
    "  word_length = [ len(word.translate(str.maketrans('', '', string.punctuation)))  for word in (s.replace('-',' ')).split() if word.translate(str.maketrans('', '', string.punctuation)).isalpha()]\n",
    "  # the code line above returns an array with the length of every word where we have removed any sort of punctation in each word\n",
    "  a = np.asarray(word_length)\n",
    "  a = a[a>0] # here we remove the words of length 0 , this is the kind of words with only punctuation in it .\n",
    "  return np.mean(a)\n",
    "\n",
    "def largestWord_length(s):\n",
    "    words_length = [ len(word.translate(str.maketrans('', '', string.punctuation)))  for word in (s.replace('-',' ')).split() if word.translate(str.maketrans('', '', string.punctuation)).isalpha()]\n",
    "    # Sort the words in increasing\n",
    "    # order of their lengths\n",
    "    if len(words_length) == 0 :\n",
    "      return 0\n",
    "    words_length.sort() \n",
    "    return words_length[-1]\n",
    "def numberOfPunctuation(s) : \n",
    "  count = lambda l1,l2: sum([1 for x in l1 if x in l2])\n",
    "  return count(s,set(string.punctuation))\n",
    "\n",
    "def removeBracket(s) : # this function is used to delete any bracket caracters in a string\n",
    "     s = s.translate(str.maketrans('','','[]'))\n",
    "     return s\n",
    "\n",
    "def repeatedElements(s) : # this method returns the number of times a word is repeated more than once in the string s\n",
    "    words = [word.translate(str.maketrans('', '', string.punctuation))  for word in (s.replace('-',' ')).split() if word.translate(str.maketrans('', '', string.punctuation)).isalpha()]\n",
    "    duplicate_dict = {i:words.count(i) for i in words}\n",
    "    return sum([v > 1 for v in duplicate_dict.values()])\n",
    "\n",
    "def numNumbers(s) : \n",
    "   return sum([word.translate(str.maketrans('', '', string.punctuation)).isnumeric() for word in (s.replace('-',' ')).split()])\n",
    "   # returns the number of numeric words in the string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iEMdmauZJdqh",
    "outputId": "e32a35f6-4a75-4a6b-b4b5-56d79801b455"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with year : 2020\n",
      "Processing chunk with 500000 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 244449 rows\n",
      "Processing the data for 2020 took 2683.20 seconds \n",
      "Working with year : 2019\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 263302 rows\n",
      "Processing the data for 2019 took 11172.06 seconds \n",
      "Working with year : 2018\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 228451 rows\n",
      "Processing the data for 2018 took 13880.09 seconds \n",
      "Working with year : 2017\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n",
      "Processing chunk with 500000 rows\n"
     ]
    }
   ],
   "source": [
    "def process_chunk(chunk,c):\n",
    "        print(f'Processing chunk with {len(chunk)} rows')\n",
    "        # we observed in the data set that there were some anormal square bracket in some quotation\n",
    "        chunk['quotation']= chunk['quotation'].apply(removeBracket) # this will remobe those square brackets\n",
    "        chunk['numWords'] = chunk['quotation'].apply(count_words)\n",
    "        chunk['averageWordLength'] = chunk['quotation'].apply(average_word_length)\n",
    "        chunk['largestWordLength'] = chunk['quotation'].apply(largestWord_length)\n",
    "        chunk['numOfPunctuation'] = chunk['quotation'].apply(numberOfPunctuation)\n",
    "        chunk['numRepeatedWords'] = chunk['quotation'].apply(repeatedElements)\n",
    "        chunk['numNumbers'] = chunk['quotation'].apply(numNumbers)\n",
    "        chunk.to_csv(columns = ['numWords','speaker','numOccurrences','averageWordLength','largestWordLength','numOfPunctuation','numRepeatedWords','numNumbers','date'],path_or_buf=\"quotes-%s.csv\"%c,sep =';',mode= 'a',float_format='%.2f')\n",
    "        \n",
    "for year in range(2020,2014,-1) :\n",
    "   print(\"Working with year : \" + str(year))\n",
    "   start = time.time()\n",
    "   df = pd.read_json(\"/content/drive/MyDrive/Quotebank/quotes-%s.json.bz2\"%year, lines=True, compression='bz2',chunksize=500000)\n",
    "   for chunk in df:\n",
    "      process_chunk(chunk,year)\n",
    "\n",
    "   end = time.time() \n",
    "   diff = end - start\n",
    "   print(\"Processing the data for %s took %.2f seconds \"%(year,diff))         \n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "intro_data_handling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
